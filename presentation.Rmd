---
title: "Descriptive mAchine Learning EXplanations: Bigger on the inside"
subtitle: "add link to public repo"
author: "Frankie Logan"
date: "10-1-2018"
output:
  xaringan::moon_reader:
    css: ["default", "default-fonts", "hygge"]
    lib_dir: dist/libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

class: top, left

# Motivation

- Machine Learning (ML) models are wonderful tools that can help us tackle a wide variety of problem. However, the more
sopisticated they become, the more obscure they become to the end users. 

- Too obscure for many business use case?  


```{r echo = FALSE}
knitr::include_graphics("img/black_box.jpeg")
```

---
class: top, left
# Avaliable Tool (Not Exhaustive)

- [DALEX](https://github.com/pbiecek/DALEX)

- [lime](https://github.com/thomasp85/lime)

- [live](https://github.com/MI2DataLab/live)

- [pdp](https://github.com/bgreenwell/pdp)

---
class: top, left
# DALEX: Descriptive mAchine Learning EXplanations

[DALEX](https://github.com/pbiecek/DALEX) (Biecek 2018) is a [R](https://www.r-project.org/) package that is created by Przemyslaw Biecek that provides us with the tools "unbox" all the wonderful models

What makes DALEX so special?

- wide array of diagnostic capabilities pack into one
- adaptability
- [ggplot2](https://ggplot2.tidyverse.org/) (Wickham)

Additional Resource: [https://pbiecek.github.io/DALEX_docs/](https://pbiecek.github.io/DALEX_docs/) (Biecek Aug 2018)

---
class: top, left


# DALEX capabilities

- Model Performance (`model_performance()`)

  * How good is your model?

- Variable Importance (`variable_importance()`)

  * Which variable are the most important in your model? 

- Variable Response (`variable_response()`)

  * What is the relationship between the variable and the prediction?
  * [pdp](https://github.com/bgreenwell/pdp), [ale](https://cran.r-project.org/web/packages/ALEPlot/index.html), [factor](https://github.com/MI2DataLab/factorMerger)

- Prediction breakdown (`prediction_breakdown()`)

  * What is the exact effect of each variables?
  

Additional resources:

- https://journal.r-project.org/archive/2017/RJ-2017-016/RJ-2017-016.pdf
- https://arxiv.org/abs/1709.04412
- https://arxiv.org/abs/1804.01955


---
class: inverse, middle, center
# Let's see how it works in practice!

---
class: top left
# Data/Model Prepping

Explain function:

```{r eval=FALSE, echo=TRUE}

explain(model, data, y, predict_function, label)

```

e.g.

```{r eval=FALSE, echo=TRUE}
explainer_nn <- explain(
  model, data = select(validation, predictors),
  y = validation$lapse_count_rate,
  predict_function = custom_predict_nn,
  label = "Neural Network (Keras)"
)
```
---
class: top left
# Model Performance (model_performance)

```{r eval = FALSE, echo = TRUE}
mp_nn <- model_performance(explainer_nn)

mp_xgb_model <- model_performance(explainer_xgb)

mp_glm <- model_performance(explainer_glm)

mp_h2o <- model_performance(explainer_h2o_rf)

plot(mp_xgb_model, mp_glm, mp_nn, mp_h2o)
```

.pull-left[
```{r echo=FALSE}
knitr::include_graphics("img/mp_all.jpeg")
```

]
.pull-right[
```{r echo = FALSE}
knitr::include_graphics("img/box_mp.jpeg")
```

]
---
class: top, left

<style type="text/css">
code.r{
  font-size: 14px;
}
</style>

# Single Prediction (prediction_breakdown)

.pull-left[

Unlike GLM & LM, we don't have coefficient output to help us measure how each predictor affect the final output.  Single Prediction function allow us to examine how each predictor are affecting one prediction. 

- caveat: It doesn't handle models with too many interactions term well!
]

.pull-right[

```{r eval = FALSE, echo = TRUE}
newdata <- validation[25,] %>% 
  select(predictors)

pb_xgb <- prediction_breakdown(explainer = explainer_xgb, 
                              observation = newdata)

plot(pb_xgb)
```

```{r echo = FALSE}

knitr::include_graphics("img/xgb_sp.jpeg")

```

]

---
class: top, left

<style type="text/css">
code.r{
  font-size: 14px;
}
</style>

# Model Prediction Comparison

.pull-left[

```{r eval = FALSE, echo = TRUE}
pb_xgb <- prediction_breakdown(explainer_xgb, 
                               observation = newdata)

pb_nn <- prediction_breakdown(explainer_nn, 
                              observation = newdata)

pb_rf <- prediction_breakdown(explainer_h2o_rf, 
                              observation = newdata_h2o)

pb_glm <- prediction_breakdown(explainer_glm, 
                               observation = newdata)

plot(pb_xgb, pb_nn, pb_rf, pb_glm)
```
]

.pull-right[

```{r out.height = 450, echo = FALSE}

knitr::include_graphics("img/all_sp.jpeg")

```
]

---

class: top, left

# Variable Importance (variable_importance)

.pull-left[
```{r eval = FALSE, echo=TRUE}
vi_nn <- variable_importance(explainer_nn, 
                             type = "ratio", 
                             n_sample = -1)
vi_xgb <- variable_importance(explainer_xgb, 
                              type = "ratio", 
                              n_sample = -1)
vi_glm1 <- variable_importance(explainer_glm, 
                               type = "ratio", 
                               n_sample = -1)
vi_h2o <- variable_importance(explainer_h2o_rf, 
                              type = "ratio", 
                              n_sample = -1)

plot(vi_xgb, vi_glm1, vi_nn, vi_h2o)

```
]

.pull-right[
```{r out.height = 400, echo = FALSE}

knitr::include_graphics("img/vi_all.jpeg")

```
]

---
class: top, left

#Merging Path Plot (variable_response)

.pull-left[
```{r eval = FALSE, echo = TRUE}
mpp_xgb <- variable_response(explainer = explainer_xgb, 
                             variable = "risk_class", 
                             type = "factor")

plot(mpp_xgb)
```
]

.pull-right[

```{r echo = FALSE}
knitr::include_graphics("img/mpp_xgb.jpeg")

```

]

---
class: top, left
#Reference

Biecek, Przemyslaw. DALEX. Descriptive MAchine Learning EXplanations, 2018, pbiecek.github.io/DALEX/.

Biecek, Przemyslaw. DALEX: Descriptive MAchine Learning EXplanations. Descriptive MAchine Learning EXplanations DALEX, 11 Aug. 2018, pbiecek.github.io/DALEX_docs/.

Greenwell, Brandon. A General Framework for Constructing Partial Dependence (I.e., Marginal Effect) Plots from Various Types Machine Learning Models in R. GitHub, 25 Sept. 2016, github.com/bgreenwell/pdp.

Wickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4, http://ggplot2.org.

Pedersen, Thomas. thomasp85/Lime. GitHub, 2017, github.com/thomasp85/lime.

Staniak, Mateusz, and Biecek Przemyslaw. Live: Local Interpretable (Model-Agnostic) Visual Explanations. GitHub, 2017, github.com/MI2DataLab/live.

