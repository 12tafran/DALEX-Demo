<!DOCTYPE html>
<html>
  <head>
    <title>Interpreting Machine Learning: Bigger on the inside</title>
    <meta charset="utf-8">
    <meta name="author" content="Frankie Logan" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Interpreting Machine Learning: Bigger on the inside
### Frankie Logan
### 10-1-2018

---



class: top, left

# Motivation

- Machine Learning (ML) models are wonderful tools that can help us tackle a wide variety of problem. However, the more
sopisticated they become, the more obscure they become to the end users. 

- Too obscure for many business cases?  


![](img/black_box.jpeg)&lt;!-- --&gt;
---
class: top, left
# White Box model vs Black Box model
--

.pull-left[

```
## # A tibble: 10 x 3
##    term                     estimate  p.value
##    &lt;chr&gt;                       &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)                0.168  1.04e-15
##  2 genderM                    0.0163 1.36e- 7
##  3 issue_age20-29             0.0550 1.62e- 5
##  4 issue_age30-39             0.0951 3.37e-14
##  5 issue_age40-49             0.175  6.77e-44
##  6 issue_age50-59             0.246  1.90e-83
##  7 issue_age60-69             0.258  1.02e-86
##  8 issue_age70+               0.273  1.23e-72
##  9 face_amountB.  100k-249k   0.0387 1.75e-14
## 10 face_amountC.  250k-999k   0.0750 4.43e-46
```
]
--
.pull-right[

![](img/black_box_lol.jpeg)&lt;!-- --&gt;
]
---
class: top, left
# Avaliable Tools (Not Exhaustive)

In recent years, a lot of tools have been developed to improve the interpretability of ML models:

--

* [DALEX](https://github.com/pbiecek/DALEX)

* [lime](https://github.com/thomasp85/lime)

* [live](https://github.com/MI2DataLab/live)

* [pdp](https://github.com/bgreenwell/pdp)

* etc...

---
class: top, left
# DALEX: Descriptive mAchine Learning EXplanations

[DALEX](https://github.com/pbiecek/DALEX) (Biecek 2018) is an [R](https://www.r-project.org/) package created by Przemyslaw Biecek that provides users with tools to "unbox" all the wonderful ML models

What makes DALEX so special?

- Wide array of diagnostic capabilities packed into one
- Adaptability
- [ggplot2](https://ggplot2.tidyverse.org/)

Additional Resource: [https://pbiecek.github.io/DALEX_docs/](https://pbiecek.github.io/DALEX_docs/)

---

class: inverse, middle, center
# Let's see how it works in practice!
---
class: inverse, middle center

# Shock Lapse in Post Level Term

---
class: top, left
# Background/housekeeping

Data: [SOA Post Level Term Lapse Study](https://www.soa.org/experience-studies/2014/research-2014-post-level-shock/)


Predictors: Gender, Issue Age, Face Amount, Post Level Premium Structure, Premium Jump Ratio, Risk Class, Premium Mode


Responses: Lapse Count Rate

---
class: top left
# Data/Model Prepping

Explain function:


```r
explain(model, data, y, predict_function, label)
```
--
Customize your predict function


```r
custom_predict_h2o &lt;- function(model, newdata)  {
  newdata_h2o &lt;- as.h2o(newdata)
  res &lt;- as.data.frame(h2o.predict(model, newdata_h2o))
  return(as.numeric(res$predict))
}
```
--
e.g.


```r
explainer_h2o_rf &lt;- explain(
  model = samplemodel,
  data = select(validation_h2o, predictors),
  y = validation_h2o$lapse_count_rate,
  predict_function = custom_predict_h2o,
  label = "Random Forest (H2O)")
```
---
class: top left
# Model Performance (model_performance())



&lt;img src="img/mp_all.jpeg" height="500" /&gt;


---
class: top, left
# Model Performance (model_performance())

&lt;img src="img/mp_box_all_outliers.jpeg" height="500" /&gt;


---

class: top, left

# Variable Importance (variable_importance())

Which variable are the most important in your model? 

--


```r
vi_nn &lt;- variable_importance(explainer_nn, type = "ratio", n_sample = -1)
plot(vi_xgb, vi_glm1, vi_nn, vi_h2o)
```

&lt;img src="img/vi_all.jpeg" height="400" /&gt;

---
class: top, left

#Merging Path Plot (variable_response())

What is the relationship between the variable and the prediction?

--

.pull-left[

```r
mpp_xgb &lt;- variable_response(explainer = explainer_xgb, 
                             variable = "risk_class", 
                             type = "factor")

plot(mpp_xgb)
```

Merging Path Plot utilizes [factorMerger](https://mi2datalab.github.io/factorMerger/) and is one of the three options used for investigating relationship between a single variable to the predictors.  
  
  * For continuous variable, change `type` argument to [pdp](https://github.com/bgreenwell/pdp) or [ale](https://cran.r-project.org/web/packages/ALEPlot/index.html)


Additional resources:

* [pdp paper](https://journal.r-project.org/archive/2017/RJ-2017-016/RJ-2017-016.pdf)
* [Merging Path Plot Paper](https://arxiv.org/abs/1709.04412)

]
.pull-right[

![](img/mpp_xgb.jpeg)&lt;!-- --&gt;

]
---
class: top, left

# What is the exact effect of each variables?

Let's look back at a basic GLM example


```
## # A tibble: 10 x 5
##    term                     estimate std.error statistic  p.value
##    &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 (Intercept)                0.168    0.0209       8.03 1.04e-15
##  2 genderM                    0.0163   0.00310      5.27 1.36e- 7
##  3 issue_age20-29             0.0550   0.0128       4.31 1.62e- 5
##  4 issue_age30-39             0.0951   0.0125       7.59 3.37e-14
##  5 issue_age40-49             0.175    0.0126      13.9  6.77e-44
##  6 issue_age50-59             0.246    0.0127      19.4  1.90e-83
##  7 issue_age60-69             0.258    0.0131      19.8  1.02e-86
##  8 issue_age70+               0.273    0.0151      18.1  1.23e-72
##  9 face_amountB.  100k-249k   0.0387   0.00504      7.67 1.75e-14
## 10 face_amountC.  250k-999k   0.0750   0.00526     14.3  4.43e-46
```

---
class: top, left

&lt;style type="text/css"&gt;
code.r{
  font-size: 14px;
}
&lt;/style&gt;

# Single Prediction (prediction_breakdown())

--
.pull-left[

`prediction_breakdown` uses [breakDown](https://pbiecek.github.io/breakDown/) package as a base
  * caveat: It doesn't handle models with too many interactions term well!
  

```r
newdata &lt;- validation[25,] %&gt;% 
  select(predictors)

pb_xgb &lt;- prediction_breakdown(explainer = explainer_xgb, 
                              observation = newdata)

plot(pb_xgb)
```

Additional resources:

* [live and breakDown Paper](https://arxiv.org/abs/1804.01955)

]
--
.pull-right[

![](img/xgb_sp.jpeg)&lt;!-- --&gt;

]

---
class: top, left

&lt;style type="text/css"&gt;
code.r{
  font-size: 14px;
}
&lt;/style&gt;

# Model Prediction Comparison
&lt;small&gt;Let's look at all the models side by side&lt;/small&gt;

&lt;img src="img/sp_3.jpeg" style="display: block; margin: auto;" /&gt;


---

class: top, left
&lt;style type="text/css"&gt;
body{
  font-size: 14px;
}
&lt;/style&gt;
#Reference

&lt;small&gt;Biecek, Przemyslaw. DALEX. Descriptive MAchine Learning EXplanations, 2018, https://pbiecek.github.io/DALEX/.

Biecek Przemyslaw. (2018). DALEX: explainers for complex predictive models. ArXiv e-prints. 1806.08915, https://arxiv.org/abs/1806.08915.

Biecek, Przemyslaw. DALEX: Descriptive MAchine Learning EXplanations. Descriptive MAchine Learning EXplanations DALEX, 11 Aug. 2018, https://pbiecek.github.io/DALEX_docs/.

Greenwell, Brandon. A General Framework for Constructing Partial Dependence (I.e., Marginal Effect) Plots from Various Types Machine Learning Models in R. GitHub, 25 Sept. 2016, https://github.com/bgreenwell/pdp.

Wickham H (2016). ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. ISBN 978-3-319-24277-4, http://ggplot2.org.

Pedersen, Thomas. thomasp85/Lime. GitHub, 2017, https://github.com/thomasp85/lime.

Sitko A and Biecek P (2017). The Merging Path Plot: adaptive fusing of k-groups with likelihood-based model selection. https://arxiv.org/abs/1709.04412.

Staniak M, Biecek P (2018). Explanations of Model Predictions with live and breakDown Packages. ArXiv e-prints. 1804.01955, https://arxiv.org/abs/1804.01955.

Staniak, Mateusz, and Biecek Przemyslaw. Live: Local Interpretable (Model-Agnostic) Visual Explanations. GitHub, 2017, https://github.com/MI2DataLab/live.&lt;/small&gt;

---

class: top, left

#Questions?
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
